{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Saga Choreography demonstration \u00b6 Context \u00b6 Introduced in 1987 by Hector Garcaa-Molrna Kenneth Salem paper the Saga pattern helps to support a long running transaction that can be broken up to a collection of sub transactions that can be interleaved any way with other transactions. With microservice each transaction updates data within a single service, each subsequent steps may be triggered by previous completion. Implementation explanation \u00b6 We have implemented the SAGA pattern in the Reefer Container Shipment Reference Application for the scenario where an order, to carry fresh goods from an origin port to a destination port, is created by a customer. The Choreography variant of the SAGA pattern, done with Kafka, involves strong decoupling between services, and each participant listens to facts from other services and acts on them independently. So each service will have at least one topic representing states on its own entity. In the figure below the saga is managed in the context of the order microservice in one of the business function like createOrder . The figure above illustrates that each service uses its own topic in Kafka to generate event about state changes to its own business entity. To manage the saga the Order service needs to listen to all participants topics and correlates event using the order ID as key. The Order business entity in this service supports a simple state machine as defined below: Each state transition should generate an event to the orders topic. The happy path looks like in the following sequence diagram: In this scenario, we have a long running transaction that spans across the Order Command microservice that creates the order and maintains the state of it, the Reefer manager microservice which tries to find an empty container with enough capacity in the origin port to support the order, the Voyage microservice which tries to find a voyage from the origin port to the destination port with enough capacity on the ship for the refrigerator containers. As you can see in the diagram above, the transaction does not finish until a reefer has been allocated and a voyage assigned to the order and, as a result, the order stays in pending state until all the sub transactions have successfully finished. Code repositories \u00b6 The new implementation of the services are done with Quarkus and Microprofile Messaging. Order Microservice Reefer Microsercice Voyage Microservice Each code structure is based on the domain-driven-design practice with clear separation between layers (app, domain, infrastructure) and keep the domain layer using the ubiquituous language of each domain: order, reefer, and voyage. \u2502 \u2502 \u2502 \u2514\u2500\u2500 ibm \u2502 \u2502 \u2502 \u2514\u2500\u2500 eda \u2502 \u2502 \u2502 \u2514\u2500\u2500 kc \u2502 \u2502 \u2502 \u2514\u2500\u2500 orderms \u2502 \u2502 \u2502 \u251c\u2500\u2500 app \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 OrderCommandApplication.java \u2502 \u2502 \u2502 \u251c\u2500\u2500 domain \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 Address.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderService.java \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 ShippingOrder.java \u2502 \u2502 \u2502 \u2514\u2500\u2500 infra \u2502 \u2502 \u2502 \u251c\u2500\u2500 api \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 ShippingOrderResource.java \u2502 \u2502 \u2502 \u251c\u2500\u2500 events \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 EventBase.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 order \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderCreatedEvent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderEvent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderEventProducer.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderUpdatedEvent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 OrderVariablePayload.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 reefer \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReeferAgent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReeferAllocated.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReeferEvent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReeferEventDeserializer.java \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 ReeferVariablePayload.java \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 voyage \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 VoyageAgent.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 VoyageAllocated.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 VoyageEvent.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 VoyageEventDeserializer.java \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 VoyageVariablePayload.java \u2502 \u2502 \u2502 \u2514\u2500\u2500 repo \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderRepository.java \u2502 \u2502 \u2502 \u2514\u2500\u2500 OrderRepositoryMem.java Events are defined in the infrastructure level, as well as the JAX-RS APIs. Compensation \u00b6 The SAGA pattern comes with the tradeoff that a compensation process must also be implemented in the case that one, or multiple, of the sub transactions fails or does not achieve to complete so that the system rolls back to the initial state before the transaction began. In our specific case, a new order creation transaction can fail either because we can not find a refrigerator container to be allocated to the order or we can not find a voyage to assigned to the order. No container \u00b6 When a new order creation is requested by a customer but there is not a container to be allocated to such order, either because the container(s) do not have enough capacity or there is no container available in the origin port for such order, the compensation process for the order creation transaction is quite simple. The order microservice will not get an answer from the reefer manager, anf after a certain time it will trigger the compensation flow by sending a OrderUpdate with status onHold. The voyage service which may has responded positively before that, may roll back the order to voyage relationship. No voyage \u00b6 This case is the sysmetric of the other one. The actions flow remains as expected for the SAGA transaction until the Voyages microservice is not answering after a time period or answering negatively. As a result, the Order Command microservice will transition the order to OnHold and emit an OrderUpdateEvent to inform the saga participants. In this case, the Reefer manager is one of those interested parties as it will need to kick off the compensation task, which in this case is nothing more than de-allocate the container to the order to make it available for any other coming order. Run locally \u00b6 In this repository, we have define a docker compose file that let you run the demonstration on your local computer. You need podman or docker and docker compose. docker-compose up -d Verify the data \u00b6 Look available voyages, can be seen via API or Swagger UI https://localhost:8082/q/swagger-ui curl -X 'GET' 'http://localhost:8082/api/v1/voyages' -H 'accept: application/json' | jq Look available Refrigerator containers, can be seen via API or Swagger UI https://localhost:8081/q/swagger-ui curl -X 'GET' 'http://localhost:8081/api/v1/reefers' -H 'accept: application/json' | jq Validate Order service by looking at current orders via API or Swagger UI https://localhost:8080/q/swagger-ui curl -X 'GET' 'http://localhost:8080/api/v1/orders' -H 'accept: application/json' | jq Happy path demonstration \u00b6 Execute the create order ./e2e/sendGoodOrder.sh { \"orderID\" : \"GoodOrder02\" , \"productID\" : \"P01\" , \"customerID\" : \"Customer01\" , \"quantity\" : 70 , \"pickupAddress\" :{ \"street\" : \"1st main street\" , \"city\" : \"San Francisco\" , \"country\" : \"USA\" , \"state\" : \"CA\" , \"zipcode\" : \"95051\" }, \"pickupDate\" : null , \"destinationAddress\" :{ \"street\" : \"1st horizon road\" , \"city\" : \"Shanghai\" , \"country\" : \"CH\" , \"state\" : \"S1\" , \"zipcode\" : \"95051\" }, \"expectedDeliveryDate\" : null , \"creationDate\" : \"2022-05-16\" , \"updateDate\" : \"2022-05-16\" , \"status\" : \"pending\" } Verify in Kafdrop the orders topic contains the expected CreateOrder event chrome https://localhost:9000 Verify in Kafdrop the reefers topic Verify the voyages topic The ShippingOrder should now be in assigned state as the order manager receives the two positive answers from the saga participant. Trigger the compensation tasks \u00b6 The order has a pickup city set to Boston, and there is no reefer available at that location at that time, so the Reefer service is not responding to the order. The order microservice has two timers for each topics it subscribes to. If those timer sets, it looks at existing pending orders and trigget an OrderUpdateEvent with status onHold. Send an order from Boston ./e2e/sendNonPossibleOrder.sh Verify order created event reaches voyage service: 09:45:06 INFO [ib.ed.kc.vo.in.ev.or.OrderAgent] (vert.x-eventloop-thread-5) Received order : NAOrder01 09:45:06 INFO [ib.ed.kc.vo.in.ev.vo.VoyageEventProducer] (vert.x-eventloop-thread-5) Send voyage message --> V005 ts: 1652805906035 and the reefer microservices 09:45:05 INFO [ib.ed.kc.fr.in.ev.or.OrderAgent] (vert.x-eventloop-thread-6) Received order : NAOrder01 Voyage generates an event for voyages allocated. Order microservice timeout as it does not get an answer from Reefer, so it put the order on-Hold and send an order updated event Voyage is compensated. Deploy with Event Streams on OpenShift \u00b6 Deploy the three services with an existing Event Streams deployed in the namespace cp4i-eventstreams . One time deploy \u00b6 Under gitops folder do the following make all You should get a trace like: namespace/eda-saga created serviceaccount/eda-saga-sa created role.rbac.authorization.k8s.io/secret-mgr created rolebinding.rbac.authorization.k8s.io/argocd-admin created clusterrolebinding.rbac.authorization.k8s.io/secrets-to-sa configured Now using project \"eda-saga\" on server \"https://api.poe.coc-ibm.com:6443\" . job.batch/cp-ca-secret created job.batch/cp-tls-usr-secret created kafkatopic.eventstreams.ibm.com/eda-saga-orders created kafkatopic.eventstreams.ibm.com/eda-saga-reefers created kafkatopic.eventstreams.ibm.com/eda-saga-voyages created kafkauser.eventstreams.ibm.com/saga-tls-user created serviceaccount/eda-saga-sa configured rolebinding.rbac.authorization.k8s.io/eda-saga-view created configmap/order-ms-cm created service/eda-saga-order created deployment.apps/eda-saga-order created route.route.openshift.io/eda-saga-order created configmap/reefer-ms-cm created service/eda-saga-reefer created deployment.apps/eda-saga-reefer created route.route.openshift.io/eda-saga-reefer created configmap/voyage-ms-cm created service/eda-saga-voyage created deployment.apps/eda-saga-voyage created route.route.openshift.io/eda-saga-voyage created Open order Swagger-ui chrome http:// $( oc get route eda-saga-order -o jsonpath = '{.status.ingress[].host}' ) /q/swagger-ui/ Post a valid order using the e2e script. Run the following command in e2e/poe folder export ORDER_URL = $( oc get route eda-saga-order -o jsonpath = '{.status.ingress[].host}' ) ./sendGoodOrder.sh { \"orderID\" : \"GoodOrder01\" , \"productID\" : \"P01\" , \"customerID\" : \"Customer01\" , \"quantity\" :10, \"pickupAddress\" : { \"street\" : \"1st main street\" , \"city\" : \"San Francisco\" , \"country\" : \"USA\" , \"state\" : \"CA\" , \"zipcode\" : \"95051\" } , \"pickupDate\" :null, \"destinationAddress\" : { \"street\" : \"1st horizon road\" , \"city\" : \"Shanghai\" , \"country\" : \"CH\" , \"state\" : \"S1\" , \"zipcode\" : \"95051\" } , \"expectedDeliveryDate\" :null, \"creationDate\" : \"2022-06-08\" , \"updateDate\" : \"2022-06-08\" , \"status\" : \"pending\" , \"voyageID\" :null, \"containerID\" :null } To clean up make clean GitOps with ArgoCD/Tekton \u00b6 TBD More reading Deduction-Based Polymorphism in Jackson 2.12 Smallrye - reactive messaging Saga design pattern Quarkus Kafka reference guide Quarkus SCHEDULING PERIODIC TASKS","title":"Home"},{"location":"#saga-choreography-demonstration","text":"","title":"Saga Choreography demonstration"},{"location":"#context","text":"Introduced in 1987 by Hector Garcaa-Molrna Kenneth Salem paper the Saga pattern helps to support a long running transaction that can be broken up to a collection of sub transactions that can be interleaved any way with other transactions. With microservice each transaction updates data within a single service, each subsequent steps may be triggered by previous completion.","title":"Context"},{"location":"#implementation-explanation","text":"We have implemented the SAGA pattern in the Reefer Container Shipment Reference Application for the scenario where an order, to carry fresh goods from an origin port to a destination port, is created by a customer. The Choreography variant of the SAGA pattern, done with Kafka, involves strong decoupling between services, and each participant listens to facts from other services and acts on them independently. So each service will have at least one topic representing states on its own entity. In the figure below the saga is managed in the context of the order microservice in one of the business function like createOrder . The figure above illustrates that each service uses its own topic in Kafka to generate event about state changes to its own business entity. To manage the saga the Order service needs to listen to all participants topics and correlates event using the order ID as key. The Order business entity in this service supports a simple state machine as defined below: Each state transition should generate an event to the orders topic. The happy path looks like in the following sequence diagram: In this scenario, we have a long running transaction that spans across the Order Command microservice that creates the order and maintains the state of it, the Reefer manager microservice which tries to find an empty container with enough capacity in the origin port to support the order, the Voyage microservice which tries to find a voyage from the origin port to the destination port with enough capacity on the ship for the refrigerator containers. As you can see in the diagram above, the transaction does not finish until a reefer has been allocated and a voyage assigned to the order and, as a result, the order stays in pending state until all the sub transactions have successfully finished.","title":"Implementation explanation"},{"location":"#code-repositories","text":"The new implementation of the services are done with Quarkus and Microprofile Messaging. Order Microservice Reefer Microsercice Voyage Microservice Each code structure is based on the domain-driven-design practice with clear separation between layers (app, domain, infrastructure) and keep the domain layer using the ubiquituous language of each domain: order, reefer, and voyage. \u2502 \u2502 \u2502 \u2514\u2500\u2500 ibm \u2502 \u2502 \u2502 \u2514\u2500\u2500 eda \u2502 \u2502 \u2502 \u2514\u2500\u2500 kc \u2502 \u2502 \u2502 \u2514\u2500\u2500 orderms \u2502 \u2502 \u2502 \u251c\u2500\u2500 app \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 OrderCommandApplication.java \u2502 \u2502 \u2502 \u251c\u2500\u2500 domain \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 Address.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderService.java \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 ShippingOrder.java \u2502 \u2502 \u2502 \u2514\u2500\u2500 infra \u2502 \u2502 \u2502 \u251c\u2500\u2500 api \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 ShippingOrderResource.java \u2502 \u2502 \u2502 \u251c\u2500\u2500 events \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 EventBase.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 order \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderCreatedEvent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderEvent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderEventProducer.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderUpdatedEvent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 OrderVariablePayload.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 reefer \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReeferAgent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReeferAllocated.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReeferEvent.java \u2502 \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ReeferEventDeserializer.java \u2502 \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 ReeferVariablePayload.java \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 voyage \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 VoyageAgent.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 VoyageAllocated.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 VoyageEvent.java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 VoyageEventDeserializer.java \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 VoyageVariablePayload.java \u2502 \u2502 \u2502 \u2514\u2500\u2500 repo \u2502 \u2502 \u2502 \u251c\u2500\u2500 OrderRepository.java \u2502 \u2502 \u2502 \u2514\u2500\u2500 OrderRepositoryMem.java Events are defined in the infrastructure level, as well as the JAX-RS APIs.","title":"Code repositories"},{"location":"#compensation","text":"The SAGA pattern comes with the tradeoff that a compensation process must also be implemented in the case that one, or multiple, of the sub transactions fails or does not achieve to complete so that the system rolls back to the initial state before the transaction began. In our specific case, a new order creation transaction can fail either because we can not find a refrigerator container to be allocated to the order or we can not find a voyage to assigned to the order.","title":"Compensation"},{"location":"#no-container","text":"When a new order creation is requested by a customer but there is not a container to be allocated to such order, either because the container(s) do not have enough capacity or there is no container available in the origin port for such order, the compensation process for the order creation transaction is quite simple. The order microservice will not get an answer from the reefer manager, anf after a certain time it will trigger the compensation flow by sending a OrderUpdate with status onHold. The voyage service which may has responded positively before that, may roll back the order to voyage relationship.","title":"No container"},{"location":"#no-voyage","text":"This case is the sysmetric of the other one. The actions flow remains as expected for the SAGA transaction until the Voyages microservice is not answering after a time period or answering negatively. As a result, the Order Command microservice will transition the order to OnHold and emit an OrderUpdateEvent to inform the saga participants. In this case, the Reefer manager is one of those interested parties as it will need to kick off the compensation task, which in this case is nothing more than de-allocate the container to the order to make it available for any other coming order.","title":"No voyage"},{"location":"#run-locally","text":"In this repository, we have define a docker compose file that let you run the demonstration on your local computer. You need podman or docker and docker compose. docker-compose up -d","title":"Run locally"},{"location":"#verify-the-data","text":"Look available voyages, can be seen via API or Swagger UI https://localhost:8082/q/swagger-ui curl -X 'GET' 'http://localhost:8082/api/v1/voyages' -H 'accept: application/json' | jq Look available Refrigerator containers, can be seen via API or Swagger UI https://localhost:8081/q/swagger-ui curl -X 'GET' 'http://localhost:8081/api/v1/reefers' -H 'accept: application/json' | jq Validate Order service by looking at current orders via API or Swagger UI https://localhost:8080/q/swagger-ui curl -X 'GET' 'http://localhost:8080/api/v1/orders' -H 'accept: application/json' | jq","title":"Verify the data"},{"location":"#happy-path-demonstration","text":"Execute the create order ./e2e/sendGoodOrder.sh { \"orderID\" : \"GoodOrder02\" , \"productID\" : \"P01\" , \"customerID\" : \"Customer01\" , \"quantity\" : 70 , \"pickupAddress\" :{ \"street\" : \"1st main street\" , \"city\" : \"San Francisco\" , \"country\" : \"USA\" , \"state\" : \"CA\" , \"zipcode\" : \"95051\" }, \"pickupDate\" : null , \"destinationAddress\" :{ \"street\" : \"1st horizon road\" , \"city\" : \"Shanghai\" , \"country\" : \"CH\" , \"state\" : \"S1\" , \"zipcode\" : \"95051\" }, \"expectedDeliveryDate\" : null , \"creationDate\" : \"2022-05-16\" , \"updateDate\" : \"2022-05-16\" , \"status\" : \"pending\" } Verify in Kafdrop the orders topic contains the expected CreateOrder event chrome https://localhost:9000 Verify in Kafdrop the reefers topic Verify the voyages topic The ShippingOrder should now be in assigned state as the order manager receives the two positive answers from the saga participant.","title":"Happy path demonstration"},{"location":"#trigger-the-compensation-tasks","text":"The order has a pickup city set to Boston, and there is no reefer available at that location at that time, so the Reefer service is not responding to the order. The order microservice has two timers for each topics it subscribes to. If those timer sets, it looks at existing pending orders and trigget an OrderUpdateEvent with status onHold. Send an order from Boston ./e2e/sendNonPossibleOrder.sh Verify order created event reaches voyage service: 09:45:06 INFO [ib.ed.kc.vo.in.ev.or.OrderAgent] (vert.x-eventloop-thread-5) Received order : NAOrder01 09:45:06 INFO [ib.ed.kc.vo.in.ev.vo.VoyageEventProducer] (vert.x-eventloop-thread-5) Send voyage message --> V005 ts: 1652805906035 and the reefer microservices 09:45:05 INFO [ib.ed.kc.fr.in.ev.or.OrderAgent] (vert.x-eventloop-thread-6) Received order : NAOrder01 Voyage generates an event for voyages allocated. Order microservice timeout as it does not get an answer from Reefer, so it put the order on-Hold and send an order updated event Voyage is compensated.","title":"Trigger the compensation tasks"},{"location":"#deploy-with-event-streams-on-openshift","text":"Deploy the three services with an existing Event Streams deployed in the namespace cp4i-eventstreams .","title":"Deploy with Event Streams on OpenShift"},{"location":"#one-time-deploy","text":"Under gitops folder do the following make all You should get a trace like: namespace/eda-saga created serviceaccount/eda-saga-sa created role.rbac.authorization.k8s.io/secret-mgr created rolebinding.rbac.authorization.k8s.io/argocd-admin created clusterrolebinding.rbac.authorization.k8s.io/secrets-to-sa configured Now using project \"eda-saga\" on server \"https://api.poe.coc-ibm.com:6443\" . job.batch/cp-ca-secret created job.batch/cp-tls-usr-secret created kafkatopic.eventstreams.ibm.com/eda-saga-orders created kafkatopic.eventstreams.ibm.com/eda-saga-reefers created kafkatopic.eventstreams.ibm.com/eda-saga-voyages created kafkauser.eventstreams.ibm.com/saga-tls-user created serviceaccount/eda-saga-sa configured rolebinding.rbac.authorization.k8s.io/eda-saga-view created configmap/order-ms-cm created service/eda-saga-order created deployment.apps/eda-saga-order created route.route.openshift.io/eda-saga-order created configmap/reefer-ms-cm created service/eda-saga-reefer created deployment.apps/eda-saga-reefer created route.route.openshift.io/eda-saga-reefer created configmap/voyage-ms-cm created service/eda-saga-voyage created deployment.apps/eda-saga-voyage created route.route.openshift.io/eda-saga-voyage created Open order Swagger-ui chrome http:// $( oc get route eda-saga-order -o jsonpath = '{.status.ingress[].host}' ) /q/swagger-ui/ Post a valid order using the e2e script. Run the following command in e2e/poe folder export ORDER_URL = $( oc get route eda-saga-order -o jsonpath = '{.status.ingress[].host}' ) ./sendGoodOrder.sh { \"orderID\" : \"GoodOrder01\" , \"productID\" : \"P01\" , \"customerID\" : \"Customer01\" , \"quantity\" :10, \"pickupAddress\" : { \"street\" : \"1st main street\" , \"city\" : \"San Francisco\" , \"country\" : \"USA\" , \"state\" : \"CA\" , \"zipcode\" : \"95051\" } , \"pickupDate\" :null, \"destinationAddress\" : { \"street\" : \"1st horizon road\" , \"city\" : \"Shanghai\" , \"country\" : \"CH\" , \"state\" : \"S1\" , \"zipcode\" : \"95051\" } , \"expectedDeliveryDate\" :null, \"creationDate\" : \"2022-06-08\" , \"updateDate\" : \"2022-06-08\" , \"status\" : \"pending\" , \"voyageID\" :null, \"containerID\" :null } To clean up make clean","title":"One time deploy"},{"location":"#gitops-with-argocdtekton","text":"TBD More reading Deduction-Based Polymorphism in Jackson 2.12 Smallrye - reactive messaging Saga design pattern Quarkus Kafka reference guide Quarkus SCHEDULING PERIODIC TASKS","title":"GitOps with ArgoCD/Tekton"},{"location":"CONTRIBUTING/","text":"Contributing to IBM Cloud Architecture reference applications \u00b6 Anyone can contribute to IBM Cloud Architecture reference applications and their associated projects, whether you are an IBMer or not. We welcome your collaboration & contributions happily, as our reference applications are meant to reflect your real world scenarios. There are multiple ways to contribute: report bugs and improvement suggestions, improve documentation, and contribute code. Bug reports, documentation changes, and feature requests \u00b6 If you would like to contribute your experience with an IBM Cloud Architecture project back to the project in the form of encountered bug reports, necessary documentation changes, or new feature requests, this can be done through the use of the repository's Issues list. Before opening a new issue, please reference the existing list to make sure a similar or duplicate item does not already exist. Otherwise, please be as explicit as possible when creating the new item and be sure to include the following: Bug reports Specific Project Version Deployment environment A minimal, but complete, setup of steps to recreate the problem Documentation changes URL to existing incorrect or incomplete documentation (either in the project's GitHub repo or external product documentation) Updates required to correct current inconsistency If possible, a link to a project fork, sample, or workflow to expose the gap in documentation. Feature requests Complete description of project feature request, including but not limited to, components of the existing project that are impacted, as well as additional components that may need to be created. A minimal, but complete, setup of steps to recreate environment necessary to identify the new feature's current gap. The more explicit and thorough you are in opening GitHub Issues, the more efficient your interaction with the maintainers will be. When creating the GitHub Issue for your bug report, documentation change, or feature request, be sure to add as many relevant labels as necessary (that are defined for that specific project). These will vary by project, but will be helpful to the maintainers in quickly triaging your new GitHub issues. Code contributions \u00b6 We really value contributions, and to maximize the impact of code contributions, we request that any contributions follow the guidelines below. If you are new to open source contribution and would like some more pointers or guidance, you may want to check out Your First PR and First Timers Only . These are a few projects that help on-board new contributors to the overall process. Coding and Pull Requests best practices \u00b6 Please ensure you follow the coding standard and code formatting used throughout the existing code base. This may vary project by project, but any specific diversion from normal language standards will be explicitly noted. One feature / bug fix / documentation update per pull request Always pull the latest changes from upstream and rebase before creating any pull request. New pull requests should be created against the integration branch of the repository, if available. This ensures new code is included in full-stack integration tests before being merged into the master branch All new features must be accompanied by associated tests. Make sure all tests pass locally before submitting a pull request. Include tests with every feature enhancement, improve tests with every bug fix Github and git flow \u00b6 The internet is littered with guides and information on how to use and understand git. However, here's a compact guide that follows the suggested workflow Fork the desired repo in github. Clone your repo to your local computer. Add the upstream repository Note: Guide for step 1-3 here: forking a repo Create new development branch off the targeted upstream branch. This will often be master . git checkout -b <my-feature-branch> master Do your work: Write your code Write your tests Pass your tests locally Commit your intermediate changes as you go and as appropriate Repeat until satisfied Fetch latest upstream changes (in case other changes had been delivered upstream while you were developing your new feature). git fetch upstream 7. Rebase to the latest upstream changes, resolving any conflicts. This will 'replay' your local commits, one by one, after the changes delivered upstream while you were locally developing, letting you manually resolve any conflict. git branch --set-upstream-to=upstream/master git rebase Instructions on how to manually resolve a conflict and commit the new change or skip your local replayed commit will be presented on screen by the git CLI. Push the changes to your repository git push origin <my-feature-branch> Create a pull request against the same targeted upstream branch. Creating a pull request Once the pull request has been reviewed, accepted and merged into the main github repository, you should synchronise your remote and local forked github repository master branch with the upstream master branch. To do so: Pull to your local forked repository the latest changes upstream (that is, the pull request). git pull upstream master Push those latest upstream changes pulled locally to your remote forked repository. git push origin master What happens next? \u00b6 All pull requests will be automatically built and unit tested by travis-ci, when implemented by that specific project. You can determine if a given project is enabled for travis-ci unit tests by the existence of a .travis.yml file in the root of the repository or branch. When in use, all travis-ci unit tests must pass completely before any further review or discussion takes place. The repository maintainer will then inspect the commit and, if accepted, will pull the code into the upstream branch. Should a maintainer or reviewer ask for changes to be made to the pull request, these can be made locally and pushed to your forked repository and branch. Commits passing this stage will make it into the next release cycle for the given project.","title":"CONTRIBUTING"},{"location":"CONTRIBUTING/#contributing-to-ibm-cloud-architecture-reference-applications","text":"Anyone can contribute to IBM Cloud Architecture reference applications and their associated projects, whether you are an IBMer or not. We welcome your collaboration & contributions happily, as our reference applications are meant to reflect your real world scenarios. There are multiple ways to contribute: report bugs and improvement suggestions, improve documentation, and contribute code.","title":"Contributing to IBM Cloud Architecture reference applications"},{"location":"CONTRIBUTING/#bug-reports-documentation-changes-and-feature-requests","text":"If you would like to contribute your experience with an IBM Cloud Architecture project back to the project in the form of encountered bug reports, necessary documentation changes, or new feature requests, this can be done through the use of the repository's Issues list. Before opening a new issue, please reference the existing list to make sure a similar or duplicate item does not already exist. Otherwise, please be as explicit as possible when creating the new item and be sure to include the following: Bug reports Specific Project Version Deployment environment A minimal, but complete, setup of steps to recreate the problem Documentation changes URL to existing incorrect or incomplete documentation (either in the project's GitHub repo or external product documentation) Updates required to correct current inconsistency If possible, a link to a project fork, sample, or workflow to expose the gap in documentation. Feature requests Complete description of project feature request, including but not limited to, components of the existing project that are impacted, as well as additional components that may need to be created. A minimal, but complete, setup of steps to recreate environment necessary to identify the new feature's current gap. The more explicit and thorough you are in opening GitHub Issues, the more efficient your interaction with the maintainers will be. When creating the GitHub Issue for your bug report, documentation change, or feature request, be sure to add as many relevant labels as necessary (that are defined for that specific project). These will vary by project, but will be helpful to the maintainers in quickly triaging your new GitHub issues.","title":"Bug reports, documentation changes, and feature requests"},{"location":"CONTRIBUTING/#code-contributions","text":"We really value contributions, and to maximize the impact of code contributions, we request that any contributions follow the guidelines below. If you are new to open source contribution and would like some more pointers or guidance, you may want to check out Your First PR and First Timers Only . These are a few projects that help on-board new contributors to the overall process.","title":"Code contributions"},{"location":"CONTRIBUTING/#coding-and-pull-requests-best-practices","text":"Please ensure you follow the coding standard and code formatting used throughout the existing code base. This may vary project by project, but any specific diversion from normal language standards will be explicitly noted. One feature / bug fix / documentation update per pull request Always pull the latest changes from upstream and rebase before creating any pull request. New pull requests should be created against the integration branch of the repository, if available. This ensures new code is included in full-stack integration tests before being merged into the master branch All new features must be accompanied by associated tests. Make sure all tests pass locally before submitting a pull request. Include tests with every feature enhancement, improve tests with every bug fix","title":"Coding and Pull Requests best practices"},{"location":"CONTRIBUTING/#github-and-git-flow","text":"The internet is littered with guides and information on how to use and understand git. However, here's a compact guide that follows the suggested workflow Fork the desired repo in github. Clone your repo to your local computer. Add the upstream repository Note: Guide for step 1-3 here: forking a repo Create new development branch off the targeted upstream branch. This will often be master . git checkout -b <my-feature-branch> master Do your work: Write your code Write your tests Pass your tests locally Commit your intermediate changes as you go and as appropriate Repeat until satisfied Fetch latest upstream changes (in case other changes had been delivered upstream while you were developing your new feature). git fetch upstream 7. Rebase to the latest upstream changes, resolving any conflicts. This will 'replay' your local commits, one by one, after the changes delivered upstream while you were locally developing, letting you manually resolve any conflict. git branch --set-upstream-to=upstream/master git rebase Instructions on how to manually resolve a conflict and commit the new change or skip your local replayed commit will be presented on screen by the git CLI. Push the changes to your repository git push origin <my-feature-branch> Create a pull request against the same targeted upstream branch. Creating a pull request Once the pull request has been reviewed, accepted and merged into the main github repository, you should synchronise your remote and local forked github repository master branch with the upstream master branch. To do so: Pull to your local forked repository the latest changes upstream (that is, the pull request). git pull upstream master Push those latest upstream changes pulled locally to your remote forked repository. git push origin master","title":"Github and git flow"},{"location":"CONTRIBUTING/#what-happens-next","text":"All pull requests will be automatically built and unit tested by travis-ci, when implemented by that specific project. You can determine if a given project is enabled for travis-ci unit tests by the existence of a .travis.yml file in the root of the repository or branch. When in use, all travis-ci unit tests must pass completely before any further review or discussion takes place. The repository maintainer will then inspect the commit and, if accepted, will pull the code into the upstream branch. Should a maintainer or reviewer ask for changes to be made to the pull request, these can be made locally and pushed to your forked repository and branch. Commits passing this stage will make it into the next release cycle for the given project.","title":"What happens next?"}]}